# -*- coding: utf-8 -*-
"""自動学習AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-un71xSvPV42BTWks9wkEiYGEk0yrfA
"""

!nvidia-smi

!pip install -q \
autodistill \
autodistill-grounded-sam \
autodistill-yolov8 \
roboflow \
supervision==0.9.0 \
pip-review \
tqdm \
joblib \
pandas \
numpy \
scipy \
xlrd \
XlsxWriter \
matplotlib \
japanize-matplotlib \
Pillow \
opencv-python \
folium \
plotly \
wordcloud \
requests \
beautifulsoup4 \
lxml \
Flask \
Flask-Bootstrap4 \
PyMySQL \
PyInstaller

import os
HOME = os.getcwd()
print(HOME)

!mkdir {HOME}/images

!pip install -q icrawler autodistill autodistill-grounded-sam autodistill-yolov8 roboflow supervision==0.9.0

from google.colab import drive
drive.mount('/content/drive')

!pip install icrawler

!pip install googletrans==4.0.0-rc1

from icrawler.builtin import BingImageCrawler
import os
import requests
import json
import time

GEMINI_API = "AIzaSyD_ADF3TDftzquA8Qt250za6HL6hsJji9E"

# Function to send an email notification
def send_email(api_url, recipient, subject, body):
    headers = {
        'Content-Type': 'application/json'
    }
    data = {
        'recipient': recipient,
        'subject': subject,
        'body': body
    }

    response = requests.post(api_url, headers=headers, data=json.dumps(data))

    if response.status_code == 200:
        print("Email sent successfully.")
    else:
        print(f"Failed to send email. Status code: {response.status_code}")
        print("Response:", response.text)

# Function to count existing images in a directory
def count_existing_images(root_dir):
    files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]
    return len(files)

# Function to download images for each keyword
def download_images(keywords, num_images):
    root_dir = os.path.join(r"/content/drive/MyDrive/学習データ")  # Save directory path
    os.makedirs(root_dir, exist_ok=True)
    existing_count = count_existing_images(root_dir)

    for keyword in keywords:
        print(f"Downloading images for keyword: {keyword}")
        crawler = BingImageCrawler(storage={'root_dir': root_dir})
        crawler.crawl(keyword=keyword, max_num=num_images, file_idx_offset=existing_count)
        existing_count += num_images
        time.sleep(1)  # Pause to avoid triggering rate limits

    return existing_count

# Main process to execute the image download and send an email notification
def main():
    api_url = 'https://script.google.com/home/projects/1NwgECOGjlUXGqCTfQvyc0XQlomT6AQeg-vDj_EYmODXP8x4YFLHyYidP/edit'
    recipient_email = 'hikari.42114@gmail.com'
    subject = 'クローニングが完了しました'

    # List of keywords to download images for
    TEXT_PROMPTS = [
        'text', 'mirror', 'window', 'cardboard', 'poster', 'sign', 'manhole',
        'logo', 'signboard', 'utility pole', 'Name tag', 'License plate', 'card', 'Mail or envelope',
        'Digital screens', 'QR codes', 'barcodes', 'documents', 'information board', 'Map', 'Famous landmark'
    ]

    num_images_per_keyword = 3000  # Number of images to download for each keyword

    # Start downloading images
    total_images_downloaded = download_images(TEXT_PROMPTS, num_images_per_keyword)

    # Send email notification after the completion
    send_email(api_url, recipient_email, subject, f'{total_images_downloaded}枚の画像のダウンロードが完了しました')

if __name__ == "__main__":
    main()

!rm -r '/content/D:\R06procon\学習用データ（クローニング）'

from icrawler.builtin import GoogleImageCrawler
import datetime

n_total_images = 10000
n_per_crawl = 100

delta = datetime.timedelta(days=360)
end_day = datetime.datetime(2023, 1, 29)

def datetime2tuple(date):
    return (date.year, date.month, date.day)

for i in range(int(n_total_images / n_per_crawl )):
    start_day = end_day - delta
    google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': '/path/to/image'})
    google_crawler.crawl(keyword='pengin', filters={'date':(datetime2tuple(start_day), datetime2tuple(end_day))}, file_idx_offset=i*n_per_crawl , max_num=n_per_crawl)
    end_day = start_day - datetime.timedelta(days=1)

!mkdir   '/content/drive/MyDrive/学習データ'

import os
import shutil

def move_and_rename_images(src_folder, dest_folder):
    # 保存先のフォルダがなければ作成
    os.makedirs(dest_folder, exist_ok=True)

    # 連番用カウンター
    counter = 1

    # 入れ子状のフォルダからすべての画像を探す
    for root, dirs, files in os.walk(src_folder):
        for file in files:
            # ファイル拡張子を確認して画像ファイルのみ処理
            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
                # 新しいファイル名を連番で設定
                new_filename = f"image_{str(counter).zfill(6)}{os.path.splitext(file)[1]}"
                counter += 1

                # 元のファイルのパスと新しいファイルのパスを指定
                original_path = os.path.join(root, file)
                new_path = os.path.join(dest_folder, new_filename)

                # 画像ファイルを新しいフォルダに移動し、リネーム
                shutil.move(original_path, new_path)
                print(f"Moved and renamed: {original_path} -> {new_path}")

# 関数を実行して画像をまとめてリネーム
move_and_rename_images(output_path, output_path)

import locale
locale.getpreferredencoding = lambda: "UTF-8"

!pip install ultralytics

!pip install --upgrade ultralytics

from autodistill.detection import CaptionOntology
from autodistill_grounded_sam import GroundedSAM
import supervision as sv
import torch
# ラベルの対応関係を定義
ontology = CaptionOntology({
    'text': 'text',
    'mirror':'mirror',
    'window':'window',
    'cardboard': 'cardboard',
    'poster': 'poster',
    'sign':'sign',
    'manhole': 'manhole',
    'logo':'logo',
    'signboard':'signboard',
    'Name tag':'Name tag',
    'License plate':'License plate',
    'card':'card',
    'Mail or envelope':'Mail or envelope',
    'Digital screens':'Digital screens',
    'QR codes':'QR codes',
    'barcodes':'barcodes',
    'documents':'documents',
    'information board':'information board',
    'Map':'Map',
    "utility pole": "electricity pole",
    "bus stop": "bus-stop"
})

# ディレクトリパスを設定
IMAGE_DIR_PATH = "images"
DATASET_DIR_PATH = "dataset"
torch.use_deterministic_algorithms(False, warn_only=True)

# Grounded SAMを使ってラベル付けを実行
base_model = GroundedSAM(ontology=ontology)
import os
import shutil

def process_individual_files(input_folder, output_folder, batch_size=10, extension=".jpg"):
    files = [f for f in os.listdir(input_folder) if f.endswith(extension)]
    total_files = len(files)
    import torch




    for i in range(0, total_files, batch_size):

        batch_files = files[i:i + batch_size]
        print(f"Processing batch {i // batch_size + 1}/{(total_files + batch_size - 1) // batch_size}")
        # 確認のため、処理されるファイルのリストを出力


        # 一時フォルダにバッチごとの画像をコピー
        temp_input_folder = os.path.join(input_folder, "temp")
        if not os.path.exists(temp_input_folder):
            os.makedirs(temp_input_folder)
         # CUDAのAMPキャスト方法を修正
        with torch.amp.autocast("cuda"):
            base_model.label(
                input_folder=temp_input_folder,
                extension=extension,
                output_folder=output_folder
            )
        torch.utils.checkpoint.use_reentrant = False
        for file in batch_files:
            shutil.copy(os.path.join(input_folder, file), os.path.join(temp_input_folder, file))

        # バッチ処理
        base_model.label(
            input_folder=temp_input_folder,
            extension=extension,
            output_folder=output_folder
        )

        # 一時フォルダをクリア
        shutil.rmtree(temp_input_folder)

# バッチサイズを調整
batch_size = 10
process_individual_files(IMAGE_DIR_PATH, DATASET_DIR_PATH, batch_size=batch_size)

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # GPU 0 を有効にする

!nvcc --version
!nvidia-smi

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

import torch
print(torch.__version__)
print(torch.cuda.is_available())

from autodistill_yolov8 import YOLOv8
import numpy as np
import torch


# YOLOv8のモデルをロード
target_model = YOLOv8("yolov8n.pt")

# データセットのパスを設定
DATA_YAML_PATH = "dataset/data.yaml"

# ラベルのデータ形式を確認し、リストに変換する関数
def convert_labels_to_list(labels):
    if isinstance(labels, np.ndarray):
        return labels.tolist()
    return labels

# データのロードと型確認（デバッグ用）
def load_data_with_label_conversion(data_loader):
    for batch in data_loader:
        batch['labels'] = convert_labels_to_list(batch['labels'])
        yield batch

# YOLOv8でトレーニングを実行
try:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    target_model.train(DATA_YAML_PATH, epochs=500, device=device)

    print("学習が完了しました。")
except TypeError as e:
    print(f"エラーが発生しました: {e}")

import locale
locale.getpreferredencoding = lambda: "UTF-8"
!cp -r runs/detect/train2/content/drive/MyDrive/

!pip install gradio

!pip3 install torch torchvision torchaudio

!pip uninstall torch torchvision torchaudio

!mv '/content/dataset' '/content/drive/MyDrive'

import os
# 保存先のディレクトリを指定（任意の場所に変更可能）
SAVE_DIR = "/content/drive/MyDrive/"  # Google Driveの例

# ディレクトリが存在しない場合は作成
os.makedirs(SAVE_DIR, exist_ok=True)

# トレーニングが終了したモデルを保存
best_model_path = "/content/runs/detect/train7/weights/best.pt"  # YOLOv8の標準保存パス
saved_model_path = os.path.join(SAVE_DIR, "yolov8n_best.pt")
os.rename(best_model_path, saved_model_path)

print(f"学習したモデルを {saved_model_path} に保存しました。")

import os

# 画像が正しいディレクトリに保存されているか確認
train_images_dir = "/content/dataset/train/images"
if not os.path.exists(train_images_dir):
    print("ディレクトリが存在しません:", train_images_dir)
else:
    image_files = os.listdir(train_images_dir)
    if len(image_files) == 0:
        print("画像がありません。")
    else:
        print(f"{len(image_files)} 枚の画像が見つかりました。")

# テスト用データのディレクトリを作成
os.makedirs("test_images", exist_ok=True)
labels=['utility_pole','bus_stop']
# テスト用のデータを収集
for label in labels:
    label_dir = f"test_images/{label.replace(' ', '_')}"
    os.makedirs(label_dir, exist_ok=True)
    crawler = BingImageCrawler(storage={'root_dir': label_dir})
    crawler.crawl(keyword=label, max_num=num_images_per_label // 5)  # テスト用に少し少なめに収集

print("テスト画像の収集が完了しました。")

# テストデータに対してラベル付けを実行
test_dataset_dir = "dataset/images"
base_model.label(
    input_folder="test_images",
    extension=".jpg",
    output_folder=test_dataset_dir
)

print("テストデータのラベル付けが完了しました。")

# ultralyticsライブラリからYOLOクラスをインポート
from ultralytics import YOLO

# 学習済みモデルをロード
trained_model = YOLO("yolov8n.pt")

# テストデータで評価を実行
results = trained_model.predict(source=test_dataset_dir , save=False)

# 推論結果の一部を出力 (例として各画像の予測結果を確認)
for result in results:
    print(f"Image: {result['image']}")
    print(f"Boxes: {result['boxes']}")
    print(f"Scores: {result['scores']}")

from IPython.display import Image

# 混同行列の表示
Image(filename=f'{HOME}/runs/val/confusion_matrix.png', width=600)

# 評価結果の画像の表示
Image(filename=f'{HOME}/runs/val/val_batch0_pred.jpg', width=600)